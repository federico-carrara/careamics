{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Î»Split on Neuron&Astrocytes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal, Optional, Sequence\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from careamics.config import DataConfig, TrainingConfig\n",
    "from careamics.config import VAEAlgorithmConfig\n",
    "from careamics.config.architectures import LVAEModel\n",
    "from careamics.config.likelihood_model import (\n",
    "    GaussianLikelihoodConfig,\n",
    "    NMLikelihoodConfig,\n",
    ")\n",
    "from careamics.config.loss_model import LVAELossConfig, KLLossConfig\n",
    "from careamics.config.nm_model import GaussianMixtureNMConfig, MultiChannelNMConfig\n",
    "from careamics.config.optimizer_models import LrSchedulerModel, OptimizerModel\n",
    "from careamics.dataset import InMemoryDataset\n",
    "from careamics.dataset.dataset_utils.readers.astro_neurons import get_fnames\n",
    "from careamics.lightning import VAEModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Parameters\n",
    "loss_type: Optional[Literal[\"musplit\", \"denoisplit\", \"denoisplit_musplit\", \"lambdasplit\"]] = \"lambdasplit\"\n",
    "\"\"\"The type of reconstruction loss (i.e., likelihood) to use.\"\"\"\n",
    "batch_size: int = 32\n",
    "\"\"\"The batch size for training.\"\"\"\n",
    "patch_size: list[int] = [64, 64]\n",
    "\"\"\"Spatial size of the input patches.\"\"\"\n",
    "norm_strategy: Literal[\"channel-wise\", \"global\"] = \"channel-wise\"\n",
    "\"\"\"Normalization strategy for the input data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Parameters\n",
    "DATA_DIR = \"/group/jug/federico/data/neurons_and_astrocytes\"\n",
    "\"\"\"Directory containing the input data.\"\"\"\n",
    "dset_type: Literal[\"astrocytes\", \"neurons\"] = \"astrocytes\"\n",
    "\"\"\"The type of dataset to use.\"\"\"\n",
    "img_type : Literal[\"raw\", \"unmixed\"]\n",
    "\"\"\"The type of image to load, i.e., either raw multispectral or unmixed stacks.\"\"\"\n",
    "groups : Sequence[Literal[\"control\", \"arsenite\", \"tharps\"]] = \"control\"\n",
    "\"\"\"The groups of samples to load.\"\"\"\n",
    "dim : Literal[\"2D\", \"3D\"] = \"2D\"\n",
    "\"\"\"The dimensionality of the images to load.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "lr: float = 1e-3\n",
    "\"\"\"The learning rate for training.\"\"\"\n",
    "lr_scheduler_patience: int = 30\n",
    "\"\"\"The patience for the learning rate scheduler.\"\"\"\n",
    "earlystop_patience: int = 200\n",
    "\"\"\"The patience for the learning rate scheduler.\"\"\"\n",
    "max_epochs: int = 400\n",
    "\"\"\"The maximum number of epochs to train for.\"\"\"\n",
    "num_workers: int = 4\n",
    "\"\"\"The number of workers to use for data loading.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional not to touch parameters\n",
    "multiscale_count: int = 1\n",
    "\"\"\"The number of LC inputs plus one (the actual input).\"\"\"\n",
    "predict_logvar: Optional[Literal[\"pixelwise\"]] = None\n",
    "\"\"\"Whether to compute also the log-variance as LVAE output.\"\"\"\n",
    "nm_paths: Optional[tuple[str]] = [\n",
    "    \"/group/jug/ashesh/training_pre_eccv/noise_model/2402/221/GMMNoiseModel_ER-GT_all.mrc__6_4_Clip0.0-1.0_Sig0.125_UpNone_Norm0_bootstrap.npz\",\n",
    "    \"/group/jug/ashesh/training_pre_eccv/noise_model/2402/225/GMMNoiseModel_Microtubules-GT_all.mrc__6_4_Clip0.0-1.0_Sig0.125_UpNone_Norm0_bootstrap.npz\",\n",
    "]\n",
    "\"\"\"The paths to the pre-trained noise models for the different channels.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set up configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = TrainingConfig(\n",
    "    num_epochs=max_epochs,\n",
    "    precision=\"16-mixed\",\n",
    "    logger=\"wandb\",\n",
    "    gradient_clip_algorithm= \"value\",\n",
    "    gradient_clip_val=0.5,\n",
    "    lr=lr,\n",
    "    lr_scheduler_patience=lr_scheduler_patience,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"CYX\",\n",
    "    patch_size=patch_size,\n",
    "    batch_size=batch_size,\n",
    "    transforms=[],\n",
    "    norm_strategy=norm_strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, dset_type, \"info/metadata.json\")) as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = get_fnames(\n",
    "    data_path=DATA_DIR,\n",
    "    dset_type=\"astrocytes\",\n",
    "    img_type=\"raw\",\n",
    "    groups=[\"control\", \"arsenite\", \"tharps\"],\n",
    "    dim=\"2D\"\n",
    ")\n",
    "fnames = [Path(f) for f in fnames]\n",
    "fnames = fnames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = InMemoryDataset(\n",
    "    data_config=data_config,\n",
    "    inputs=fnames,\n",
    ")\n",
    "val_dset = train_dset.split_dataset(percentage=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_collate_fn(batch: list[torch.Tensor, None]) -> torch.Tensor:\n",
    "    inputs = [item[0] for item in batch]\n",
    "    inputs = torch.stack([torch.from_numpy(input_array) for input_array in inputs], dim=0)\n",
    "    return inputs, None\n",
    "\n",
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=unsupervised_collate_fn\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers, \n",
    "    collate_fn=unsupervised_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from careamics.utils.visualization import view3D\n",
    "# view3D([img for img in train_dset.data[:4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lambda_split_lightning_model(\n",
    "    algorithm: str,\n",
    "    loss_type: str,\n",
    "    img_size: int,\n",
    "    spectral_metadata: dict[str, Any],\n",
    "    NM_paths: Optional[list[Path]] = None,\n",
    "    training_config: TrainingConfig = TrainingConfig(),\n",
    "    data_mean: Optional[torch.Tensor] = None,\n",
    "    data_std: Optional[torch.Tensor] = None, \n",
    ") -> VAEModule:\n",
    "    \"\"\"Instantiate the lambdaSplit lightining model.\"\"\"\n",
    "    # Model config\n",
    "    lvae_config = LVAEModel(\n",
    "        architecture=\"LVAE\",\n",
    "        algorithm_type=\"unsupervised\",\n",
    "        input_shape=img_size,\n",
    "        multiscale_count=1,\n",
    "        z_dims=[128, 128, 128, 128],\n",
    "        output_channels=len(spectral_metadata[\"fluorophores\"]),\n",
    "        predict_logvar=None,\n",
    "        analytical_kl=False,\n",
    "        fluorophores=spectral_metadata[\"fluorophores\"],\n",
    "        wv_range=spectral_metadata[\"wavelength_range\"],\n",
    "        num_bins=spectral_metadata[\"num_bins\"],\n",
    "        ref_learnable=False,\n",
    "    )\n",
    "    \n",
    "    # Loss config\n",
    "    kl_loss_config = KLLossConfig(\n",
    "        rescaling=\"latent_dim\",\n",
    "        aggregation=\"mean\",\n",
    "        free_bits_coeff=0.0,\n",
    "    )\n",
    "    loss_config = LVAELossConfig(\n",
    "        loss_type=loss_type,\n",
    "        kl_params=kl_loss_config.model_dump(), # TODO: why tf needs model dump?\n",
    "    )\n",
    "\n",
    "    # Likelihoods configs\n",
    "    # gaussian likelihood\n",
    "    if loss_type in [\"musplit\", \"denoisplit_musplit\", \"lambdasplit\"]:\n",
    "        gaussian_lik_config = GaussianLikelihoodConfig(\n",
    "            predict_logvar=predict_logvar,\n",
    "            logvar_lowerbound=-5.0,  # TODO: find a better way to fix this\n",
    "        )\n",
    "    else:\n",
    "        gaussian_lik_config = None\n",
    "    # noise model likelihood\n",
    "    if loss_type in [\"denoisplit\", \"denoisplit_musplit\"]:\n",
    "        assert NM_paths is not None, \"A path to a pre-trained noise model is required.\"\n",
    "        gmm_list = []\n",
    "        for NM_path in NM_paths:\n",
    "            gmm_list.append(\n",
    "                GaussianMixtureNMConfig(\n",
    "                    model_type=\"GaussianMixtureNoiseModel\",\n",
    "                    path=NM_path,\n",
    "                )\n",
    "            )\n",
    "        noise_model_config = MultiChannelNMConfig(noise_models=gmm_list)\n",
    "        nm_lik_config = NMLikelihoodConfig(data_mean=data_mean, data_std=data_std)\n",
    "    else:\n",
    "        noise_model_config = None\n",
    "        nm_lik_config = None\n",
    "\n",
    "    # Other configs\n",
    "    opt_config = OptimizerModel(\n",
    "        name=\"Adamax\",\n",
    "        parameters={\n",
    "            \"lr\": training_config.lr,\n",
    "            \"weight_decay\": 0,\n",
    "        },\n",
    "    )\n",
    "    lr_scheduler_config = LrSchedulerModel(\n",
    "        name=\"ReduceLROnPlateau\",\n",
    "        parameters={\n",
    "            \"mode\": \"min\",\n",
    "            \"factor\": 0.5,\n",
    "            \"patience\": training_config.lr_scheduler_patience,\n",
    "            \"verbose\": True,\n",
    "            \"min_lr\": 1e-12,\n",
    "        },\n",
    "    )\n",
    " \n",
    "    # Group all configs & create model\n",
    "    vae_config = VAEAlgorithmConfig(\n",
    "        algorithm_type=\"vae\",\n",
    "        algorithm=algorithm,\n",
    "        model=lvae_config,\n",
    "        loss=loss_config.model_dump(), # TODO: why tf needs model dump?\n",
    "        gaussian_likelihood=gaussian_lik_config,\n",
    "        noise_model=noise_model_config,\n",
    "        noise_model_likelihood=nm_lik_config,\n",
    "        optimizer=opt_config,\n",
    "        lr_scheduler=lr_scheduler_config,\n",
    "    )\n",
    "    return VAEModule(algorithm_config=vae_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = create_lambda_split_lightning_model(\n",
    "    algorithm=\"lambdasplit\",\n",
    "    loss_type=loss_type,\n",
    "    img_size=patch_size[0],\n",
    "    spectral_metadata=metadata,\n",
    "    training_config=training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import socket\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from careamics.utils.io_utils import get_git_status, get_workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/group/jug/federico/lambdasplit_training/\"\n",
    "algo = \"lambdasplit\"\n",
    "lc_tag = \"with\" if multiscale_count > 1 else \"no\"\n",
    "workdir, exp_tag = get_workdir(ROOT_DIR, f\"{algo}_{lc_tag}_LC\")\n",
    "print(f\"Current workdir: {workdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logger\n",
    "custom_logger = WandbLogger(\n",
    "    name=os.path.join(socket.gethostname(), exp_tag),\n",
    "    save_dir=workdir,\n",
    "    project=\"_\".join((\"careamics\", algo)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configs and git status (for debugging)\n",
    "algo_config = lightning_model.algorithm_config\n",
    "\n",
    "with open(os.path.join(workdir, \"git_config.json\"), \"w\") as f:\n",
    "    json.dump(get_git_status(), f, indent=4)\n",
    "\n",
    "with open(os.path.join(workdir, \"algorithm_config.json\"), \"w\") as f:\n",
    "    f.write(algo_config.model_dump_json(indent=4))\n",
    "\n",
    "with open(os.path.join(workdir, \"training_config.json\"), \"w\") as f:\n",
    "    f.write(training_config.model_dump_json(indent=4))\n",
    "\n",
    "with open(os.path.join(workdir, \"data_config.json\"), \"w\") as f:\n",
    "    f.write(data_config.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Configs in WanDB\n",
    "custom_logger.experiment.config.update({\"algorithm\": algo_config.model_dump()})\n",
    "custom_logger.experiment.config.update({\"training\": training_config.model_dump()})\n",
    "custom_logger.experiment.config.update({\"data\": data_config.model_dump()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks (e.g., ModelCheckpoint, EarlyStopping, etc.)\n",
    "custom_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-6,\n",
    "        patience=training_config.earlystop_patience,\n",
    "        mode=\"min\",\n",
    "        verbose=True,\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=workdir,\n",
    "        filename=\"best-{epoch}\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=1,\n",
    "        save_last=True,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config.gradient_clip_val, training_config.gradient_clip_algorithm, training_config.precision, training_config.num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=training_config.num_epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    logger=custom_logger,\n",
    "    callbacks=custom_callbacks,\n",
    "    precision=training_config.precision,\n",
    "    gradient_clip_val=training_config.gradient_clip_val,  # only works with `accelerator=\"gpu\"`\n",
    "    gradient_clip_algorithm=training_config.gradient_clip_algorithm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 500 encountered ({\"errors\":[{\"message\":\"context deadline exceeded\",\"path\":[\"project\"]}],\"data\":{\"project\":null}}), retrying request\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:01:02.412022, resuming normal operation.\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> dev
   "source": [
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    train_dataloaders=train_dloader,\n",
    "    val_dataloaders=val_dloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_lvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
