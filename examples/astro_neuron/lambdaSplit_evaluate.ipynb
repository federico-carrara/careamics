{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Literal, Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydantic import BaseModel, ConfigDict\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from careamics.config import InferenceConfig\n",
    "from careamics.config import (\n",
    "    VAEAlgorithmConfig,\n",
    "    TrainingConfig,\n",
    "    DataConfig,\n",
    ")\n",
    "from careamics.dataset import InMemoryTiledPredDataset\n",
    "from careamics.dataset.dataset_utils.readers import load_astro_neuron_data\n",
    "from careamics.dataset.tiling import collate_tiles\n",
    "from careamics.lightning import VAEModule\n",
    "from careamics.utils.io_utils import load_config, load_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913d28f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtraLambdaParameters(BaseModel):\n",
    "    model_config = ConfigDict(\n",
    "        validate_assignment=True, validate_default=True, extra=\"allow\"\n",
    "    )\n",
    "    dset_type: Literal[\"astrocytes\", \"neurons\"]\n",
    "    \"\"\"The type of dataset to use.\"\"\"\n",
    "    img_type : Literal[\"raw\", \"unmixed\"]\n",
    "    \"\"\"The type of image to load, i.e., either raw multispectral or unmixed stacks.\"\"\"\n",
    "    groups : Sequence[Literal[\"control\", \"arsenite\", \"tharps\"]]\n",
    "    \"\"\"The groups of samples to load.\"\"\"\n",
    "    dim : Literal[\"2D\", \"3D\"] = \"2D\"\n",
    "    \"\"\"The dimensionality of the images to load.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seeds():\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Set Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/group/jug/federico/data/neurons_and_astrocytes\"\n",
    "OUT_ROOT = \"/group/jug/federico/lambdasplit_training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(OUT_ROOT, \"2411/lambdasplit_astro/0\")\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval Parameters\n",
    "mmse_count: int = 10\n",
    "\"\"\"The number of predictions to average for MMSE evaluation.\"\"\"\n",
    "tile_size: list[int] = [64, 64]\n",
    "\"\"\"The size of the portion of image we retain from inner padding/tiling.\"\"\"\n",
    "tile_overlap: list[int] = [32, 32]\n",
    "\"\"\"The actual patch size. If not specified data.image_size.\"\"\"\n",
    "psnr_type: Literal['simple', 'range_invariant'] = 'range_invariant'\n",
    "\"\"\"The type of PSNR to compute.\"\"\"\n",
    "which_ckpt: Literal['best', 'last'] = 'best'\n",
    "\"\"\"Which checkpoint to use for evaluation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0217393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional other params\n",
    "batch_size: int = 32\n",
    "\"\"\"The batch size for training.\"\"\"\n",
    "num_workers: int = 4\n",
    "\"\"\"The number of workers to use for data loading.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 1. Load configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    algo_config = VAEAlgorithmConfig(**load_config(ckpt_dir, \"algorithm\"))\n",
    "    training_config = TrainingConfig(**load_config(ckpt_dir, \"training\"))\n",
    "    data_config = DataConfig(**load_config(ckpt_dir, \"data\"))\n",
    "    with open(os.path.join(ckpt_dir, \"lambda_params.json\"), \"r\") as f:\n",
    "        lambda_params = ExtraLambdaParameters(**json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9053c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_config.model.fluorophores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 2. Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a1c6fa",
   "metadata": {},
   "source": [
    "`InMemoryTiledPredDataset` class does not allow to pass file names as input, since it doesn't provide a read file functionality. We therefore need to first load and store data into an array.\n",
    "\n",
    "Moreover, it requires an `InferenceConfig` config as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_config = InferenceConfig(\n",
    "    data_type=\"array\",\n",
    "    tile_size=tile_size,\n",
    "    tile_overlap=tile_overlap,\n",
    "    batch_size=batch_size,\n",
    "    axes=\"SCYX\",\n",
    "    image_means=data_config.image_means,\n",
    "    image_stds=data_config.image_stds,\n",
    "    tta_transforms=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: entire dset used for evaluation\n",
    "input_data = load_astro_neuron_data(\n",
    "    data_path=DATA_ROOT,\n",
    "    dset_type=lambda_params.dset_type,\n",
    "    img_type=lambda_params.img_type,\n",
    "    groups=lambda_params.groups,\n",
    "    dim=lambda_params.dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b78245",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dset = InMemoryTiledPredDataset(\n",
    "    prediction_config=pred_config,\n",
    "    inputs=input_data[:5],\n",
    ")\n",
    "del input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956557dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=collate_tiles\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = data_config.image_means\n",
    "data_std = data_config.image_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "##### GT dataset (unmixed images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = load_astro_neuron_data(\n",
    "    data_path=DATA_ROOT,\n",
    "    dset_type=lambda_params.dset_type,\n",
    "    img_type=\"unmixed\",\n",
    "    groups=lambda_params.groups,\n",
    "    dim=lambda_params.dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90217086",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = gt_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e686bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_data = gt_data[:5]\n",
    "del gt_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3. Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Note: noise model and the associated likelihood are not saved in the config, hence we need to reinitialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = VAEModule(algorithm_config=algo_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = load_model_checkpoint(ckpt_dir, which_ckpt)\n",
    "light_model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "light_model.eval()\n",
    "light_model.cuda()\n",
    "\n",
    "print('Loading weights from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in light_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Model has {count_parameters(light_model)/1000_000:.3f}M parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.utils.eval_utils import get_tiled_predictions\n",
    "from careamics.prediction_utils import stitch_prediction\n",
    "from careamics.utils.visualization import intensity_histograms, plot_splitting_results, view3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### 4.1. Get predictions for patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_patches, pred_stds, rec_patches, tiles_info = get_tiled_predictions(light_model, val_dloader, mmse_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7edb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_patches.shape, pred_stds.shape, rec_patches.shape, len(tiles_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### 4.2. Get full image predictions by stitching the predicted tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_imgs = np.concatenate(stitch_prediction(pred_patches, tiles_info))\n",
    "del pred_patches\n",
    "pred_std_imgs = np.concatenate(stitch_prediction(pred_stds, tiles_info))\n",
    "del pred_stds\n",
    "rec_imgs = np.concatenate(stitch_prediction(rec_patches, tiles_info))\n",
    "del rec_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b73777",
   "metadata": {},
   "source": [
    "#### 4.3. Visualize some of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5341b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_imgs.shape, pred_std_imgs.shape, rec_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_splitting_results(pred_imgs, gt_data, idx=0, preds_std=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "view3D(\n",
    "    imgs=[input_data[0], rec_imgs[0]],\n",
    "    axis=0, \n",
    "    titles=[\"Input\", \"Reconstruction\"], \n",
    "    jupyter=True,\n",
    "    save_path=os.path.join(OUT_ROOT, ckpt_dir, \"reconstruction_example.gif\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80c82a",
   "metadata": {},
   "source": [
    "#### 4.3. Predictions Post-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36b3d32",
   "metadata": {},
   "source": [
    "#### 4.4. Investigate Intensities and scales of inputs and predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893edd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_histograms(pred_imgs[0], 2.7e4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f52248",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_histograms(pred_imgs.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "#### 4.5. Compute metrics between predicted data and high-SNR (ground truth) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290a812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.utils.metrics import avg_range_inv_psnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Prepare data:\n",
    "- Unnormalize predictions (?) --> check what's the range of the predicted images\n",
    "\n",
    "NOTE: but actually we don't have access to the stats for the output since the algorithm is **unsupervised**. However, we can still have a look to the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it's needed\n",
    "gt_mean = gt_data.mean(axis=(0,2,3), keepdims=True)\n",
    "gt_std = gt_data.std(axis=(0,2,3), keepdims=True)\n",
    "unnorm_pred_imgs = pred_imgs * gt_std + gt_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Compute metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c15d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's outputs\")\n",
    "print(\"---------------\")\n",
    "psnr_arr = []\n",
    "for i in range(pred_imgs.shape[1]):\n",
    "    psnr_arr.append(avg_range_inv_psnr(pred_imgs[:, i], gt_data[:, i]))\n",
    "    print(f\"Range-Invariant PSNR for FP#{i+1}: {psnr_arr[-1]:.2f}\")\n",
    "print(f\"Avg Range-Invariant PSNR: {np.mean(psnr_arr):.2f}\")\n",
    "print(f\"Combined Range-Invariant PSNR: {avg_range_inv_psnr(pred_imgs, gt_data):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a593e",
   "metadata": {},
   "source": [
    "#### 5. Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0694ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = light_model.model\n",
    "mixer = model.mixer\n",
    "ref_matrix = mixer.ref_matrix.cpu().detach().numpy()\n",
    "ref_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reference matrix\n",
    "for i in range(ref_matrix.shape[1]):\n",
    "    plt.plot(ref_matrix[:, i], label=f\"FP{i+1}\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmixed = torch.tensor(gt_data[0], dtype=torch.float32).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be88bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = mixer(unmixed).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6734c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "rec_means = rec.mean(dim=(1, 2))\n",
    "ax[0].bar(range(32), rec_means.cpu().detach().numpy())\n",
    "ax[0].set_title(\"Rec mean intensities per channel\")\n",
    "\n",
    "inp_means = input_data[0].mean(axis=(1, 2))\n",
    "ax[1].bar(range(32), inp_means)\n",
    "ax[1].set_title(\"Input mean intensities per channel\")\n",
    "\n",
    "mat_means = ref_matrix.mean(axis=1)\n",
    "ax[2].bar(range(32), mat_means)\n",
    "ax[2].set_title(\"Mixing matrix intensities per channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ref_matrix[:, 0], c=\"blue\")\n",
    "plt.plot(ref_matrix[:, 1], c=\"green\")\n",
    "plt.plot(ref_matrix[:, 2], c=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc6ba4",
   "metadata": {},
   "source": [
    "Try new spectral mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.utils.spectral import FPRefMatrix, Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = Spectrum.from_fpbase(\"EGFP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddb82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned = spec.bin_intensity(32, (460, 550))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93722013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(spec.intensity, c=\"r\")\n",
    "plt.plot(binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_matrix = FPRefMatrix(\n",
    "    fp_names=model.fluorophores,\n",
    "    n_bins=32,\n",
    "    interval=(460, 550),\n",
    ")\n",
    "mat = fp_matrix.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mat[:, 0], c=\"blue\")\n",
    "plt.plot(mat[:, 1], c=\"green\")\n",
    "plt.plot(mat[:, 2], c=\"red\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_lvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
