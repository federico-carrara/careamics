{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from typing import Literal, Optional, Union\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from careamics.config.likelihood_model import NMLikelihoodConfig\n",
    "from careamics.config.nm_model import MultiChannelNMConfig\n",
    "from careamics.lightning import VAEModule\n",
    "# from careamics.lvae_training.eval_utils import (\n",
    "#     Calibration,\n",
    "#     get_calibrated_factor_for_stdev,\n",
    "    # get_dset_predictions,\n",
    "#     get_eval_output_dir,\n",
    "#     plot_calibration,\n",
    "#     plot_error,\n",
    "#     show_for_one,\n",
    "#     stitch_predictions,\n",
    "# )\n",
    "# from careamics.models.lvae.noise_models import noise_model_factory\n",
    "# from careamics.utils.metrics import (\n",
    "#     # avg_psnr,\n",
    "#     # avg_range_inv_psnr,\n",
    "#     # avg_ssim,\n",
    "#     scale_invariant_psnr,\n",
    "#     # multiscale_ssim\n",
    "# )\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seeds():\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/group/jug/federico/microsim/BIOSR_spectral_data/2410/v1/imgs/digital/\"\n",
    "OUT_ROOT = \"/group/jug/federico/lambdasplit_training/\"\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(OUT_ROOT, \"2410/lambdasplit_no_LC/0\")\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Set Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval Parameters\n",
    "mmse_count: int = 10\n",
    "\"\"\"The number of predictions to average for MMSE evaluation.\"\"\"\n",
    "image_size_for_grid_centers: int = 32\n",
    "\"\"\"The size of the portion of image we retain from inner padding/tiling.\"\"\"\n",
    "eval_patch_size: Optional[int] = 64\n",
    "\"\"\"The actual patch size. If not specified data.image_size.\"\"\"\n",
    "psnr_type: Literal['simple', 'range_invariant'] = 'range_invariant'\n",
    "\"\"\"The type of PSNR to compute.\"\"\"\n",
    "which_ckpt: Literal['best', 'last'] = 'best'\n",
    "\"\"\"Which checkpoint to use for evaluation.\"\"\"\n",
    "enable_calibration: bool = False\n",
    "\"\"\"Whether to enable calibration.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0217393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional other params\n",
    "batch_size: int = 32\n",
    "\"\"\"The batch size for training.\"\"\"\n",
    "num_workers: int = 4\n",
    "\"\"\"The number of workers to use for data loading.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 1. Load configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b237aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.config import (\n",
    "    VAEAlgorithmConfig,\n",
    "    TrainingConfig,\n",
    "    DataConfig,\n",
    ")\n",
    "from careamics.utils.io_utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    algo_config = VAEAlgorithmConfig(**load_config(ckpt_dir, \"algorithm\"))\n",
    "    training_config = TrainingConfig(**load_config(ckpt_dir, \"training\"))\n",
    "    data_config = DataConfig(**load_config(ckpt_dir, \"data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa55a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from careamics.dataset import InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76cc3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [\n",
    "    Path(DATA_DIR) / fname \n",
    "    for fname in glob.glob(os.path.join(DATA_DIR, \"*.tif\"))\n",
    "]\n",
    "fnames = sorted(fnames, key=lambda x: int(x.stem.split(\"_\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = InMemoryDataset(\n",
    "    data_config=data_config,\n",
    "    inputs=fnames,\n",
    ")\n",
    "val_dset = train_dset.split_dataset(percentage=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "956557dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_collate_fn(batch: list[torch.Tensor, None]) -> torch.Tensor:\n",
    "    inputs = [item[0] for item in batch]\n",
    "    inputs = torch.stack([torch.from_numpy(input_array) for input_array in inputs], dim=0)\n",
    "    return inputs, None\n",
    "\n",
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=unsupervised_collate_fn\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers, \n",
    "    collate_fn=unsupervised_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean = data_config.image_means\n",
    "data_std = data_config.image_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "##### GT dataset (i.e., split by fluorophore)\n",
    "\n",
    "NOTE: we cannot straightforwardly use the optical image data since images are larger (1004 vs. 251). We'd need to implement a way to dowscale them within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_DATA_DIR = \"/group/jug/federico/microsim/BIOSR_spectral_data/2410/v1/imgs/digital_pf/\"\n",
    "\n",
    "gt_fnames = [\n",
    "    Path(GT_DATA_DIR) / fname \n",
    "    for fname in glob.glob(os.path.join(GT_DATA_DIR, \"*.tif\"))\n",
    "]\n",
    "gt_fnames = sorted(gt_fnames, key=lambda x: int(x.stem.split(\"_\")[-1]))\n",
    "\n",
    "gt_data_config = deepcopy(data_config)\n",
    "gt_data_config.set_means_and_stds(image_means=None, image_stds=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fc1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_train_dset = InMemoryDataset(\n",
    "    data_config=gt_data_config,\n",
    "    inputs=gt_fnames,\n",
    ")\n",
    "gt_val_dset = gt_train_dset.split_dataset(percentage=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a47fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from careamics.utils.visualization import view3D\n",
    "\n",
    "_, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(gt_train_dset[0][0][0])\n",
    "ax[1].imshow(gt_train_dset[0][0][1])\n",
    "ax[2].imshow(gt_train_dset[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c38af",
   "metadata": {},
   "outputs": [],
   "source": [
    "view3D(train_dset[0][0], axis=0, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3. Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Note: noise model and the associated likelihood are not saved in the config, hence we need to reinitialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d218a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "from careamics.utils.io_utils import load_model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = VAEModule(algorithm_config=algo_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = load_model_checkpoint(ckpt_dir, which_ckpt)\n",
    "light_model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "light_model.eval()\n",
    "light_model.cuda()\n",
    "\n",
    "print('Loading weights from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in light_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Model has {count_parameters(light_model)/1000_000:.3f}M parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "#### 4.1. Get predictions for patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "165c12e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.utils.eval_utils import get_dset_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_patches, pred_stds = get_dset_predictions(light_model, val_dloader, mmse_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7edb3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_patches.shape, pred_stds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "view3D(pred_patches[0], axis=0, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27255a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### 4.2. Get full image predictions by stitching the predicted tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "# Stitch tiled predictions\n",
    "pred = stitch_predictions(\n",
    "    pred_tiled,\n",
    "    val_dset,\n",
    "    smoothening_pixelcount=0\n",
    ")\n",
    "\n",
    "# # Stitch predicted tiled logvar\n",
    "# if len(np.unique(logvar_tiled)) == 1:\n",
    "#     logvar = None\n",
    "# else:\n",
    "#     logvar = stitch_predictions(logvar_tiled, val_dset, smoothening_pixelcount=0) # TODO: there's a bug here\n",
    "\n",
    "# Stitch the std of the predictions (i.e., std computed on the mmse_count predictions)\n",
    "pred_std = stitch_predictions(pred_std_tiled, val_dset, smoothening_pixelcount=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80c82a",
   "metadata": {},
   "source": [
    "#### 4.3. Predictions Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Ignore (and remove) the pixels which are present in the last few rows and columns (since not multiples of patch_size)\n",
    "1. They don't come in the batches. So, in prediction, they are simply zeros. So they are being are ignored right now. \n",
    "2. For the border pixels which are on the top and the left, overlapping yields worse performance. This is becuase, there is nothing to overlap on one side. So, they are essentially zero padded. This makes the performance worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_pixels():\n",
    "    \"\"\"Get the number of ignored pixels in the predictions.\n",
    "    \n",
    "    Given the current predictions `pred`, analyze the first image std\n",
    "    to find the number of pixels that are ignored in prediction.\n",
    "    \"\"\"\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0, -ignored_pixels:, -ignored_pixels:,].std() == 0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "actual_ignored_pixels = get_ignored_pixels()\n",
    "print(f'Actual ignored pixels: {actual_ignored_pixels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_config[\"data_type\"] in [\n",
    "    DataType.OptiMEM100_014,\n",
    "    DataType.SemiSupBloodVesselsEMBL,\n",
    "    DataType.Pavia2VanillaSplitting,\n",
    "    DataType.ExpansionMicroscopyMitoTub,\n",
    "    DataType.ShroffMitoEr,\n",
    "    DataType.HTIba1Ki67\n",
    "]:\n",
    "    ignored_last_pixels = 32\n",
    "elif data_config[\"data_type\"] == DataType.BioSR_MRC:\n",
    "    ignored_last_pixels = 44\n",
    "elif data_config[\"data_type\"] == DataType.NicolaData:\n",
    "    ignored_last_pixels = 8\n",
    "else:\n",
    "    ignored_last_pixels = 0\n",
    "\n",
    "ignore_first_pixels = 0\n",
    "# assert actual_ignored_pixels <= ignored_last_pixels, f'Set ignored_last_pixels={actual_ignored_pixels}' # TODO: check this once stitching is fixed\n",
    "print(ignored_last_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = val_dset._data\n",
    "\"\"\"Data used to do evaluation againts. Shape is (N, H, W, C).\n",
    "\n",
    "NOTE: this is the original data (`dset._data`), hence not normalized!\n",
    "\"\"\"\n",
    "\n",
    "if DEBUG:\n",
    "    if 'target_idx_list' in data_config and data_config.target_idx_list is not None:\n",
    "        tar = tar[..., data_config.target_idx_list]\n",
    "\n",
    "def ignore_pixels(\n",
    "    arr: Union[np.ndarray, torch.Tensor],\n",
    "    patch_size: int\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    \"\"\"Remove pixels that are ignored in the predictions.\"\"\"\n",
    "    if arr.shape[2] % patch_size:\n",
    "        if ignore_first_pixels:\n",
    "            arr = arr[:,ignore_first_pixels:,ignore_first_pixels:]\n",
    "        if ignored_last_pixels:\n",
    "            arr = arr[:,:-ignored_last_pixels,:-ignored_last_pixels]\n",
    "    return arr\n",
    "\n",
    "pred = ignore_pixels(pred, val_dset.get_img_sz())\n",
    "tar = ignore_pixels(tar, val_dset.get_img_sz())\n",
    "if pred_std is not None:\n",
    "    pred_std = ignore_pixels(pred_std, val_dset.get_img_sz())\n",
    "\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "#### Visually compare Targets and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One random target vs predicted image (patch of shape [sz x sz])\n",
    "ncols = tar.shape[-1]\n",
    "_,ax = plt.subplots(figsize=(ncols*5, 2*5), nrows=2, ncols=ncols)\n",
    "img_idx = 0\n",
    "sz = 800\n",
    "hs = np.random.randint(tar.shape[1] - sz)\n",
    "ws = np.random.randint(tar.shape[2] - sz)\n",
    "for i in range(ncols):\n",
    "    ax[i,0].set_title(f'Target Channel {i+1}')\n",
    "    ax[i,0].imshow(tar[0, hs:hs+sz, ws:ws+sz, i])\n",
    "    ax[i,1].set_title(f'Predicted Channel {i+1}')\n",
    "    ax[i,1].imshow(pred[0, hs:hs+sz, ws:ws+sz, i])\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "# clean_ax(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = pred.shape[-1]\n",
    "img_sz = 3\n",
    "_,ax = plt.subplots(figsize=(4*img_sz,nrows*img_sz), ncols=4, nrows=nrows)\n",
    "idx = np.random.randint(len(pred))\n",
    "print(idx)\n",
    "for ch_id in range(nrows):\n",
    "    ax[ch_id,0].set_title(f'Target Channel {ch_id+1}')\n",
    "    ax[ch_id,0].imshow(tar_normalized[idx,..., ch_id], cmap='magma')\n",
    "    ax[ch_id,1].set_title(f'Predicted Channel {ch_id+1}')\n",
    "    ax[ch_id,1].imshow(pred[idx,:,:,ch_id], cmap='magma')\n",
    "    plot_error(\n",
    "        tar_normalized[idx,...,ch_id],\n",
    "        pred[idx,:,:,ch_id],\n",
    "        cmap = matplotlib.cm.coolwarm,\n",
    "        ax = ax[ch_id,2],\n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    cropsz = 256\n",
    "    h_s = np.random.randint(0, tar_normalized.shape[1] - cropsz)\n",
    "    h_e = h_s + cropsz\n",
    "    w_s = np.random.randint(0, tar_normalized.shape[2] - cropsz)\n",
    "    w_e = w_s + cropsz\n",
    "\n",
    "    plot_error(\n",
    "        tar_normalized[idx,h_s:h_e,w_s:w_e, ch_id],\n",
    "        pred[idx,h_s:h_e,w_s:w_e,ch_id],\n",
    "        cmap = matplotlib.cm.coolwarm,\n",
    "        ax = ax[ch_id,3],\n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    # Add rectangle to the region\n",
    "    rect = patches.Rectangle((w_s, h_s), w_e-w_s, h_e-h_s, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[ch_id,2].add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "#### Compute metrics between predicted data and high-SNR (ground truth) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unnorm = []\n",
    "for i in range(pred.shape[-1]):\n",
    "    if sep_std.shape[-1] == 1:\n",
    "        temp_pred_unnorm = pred[...,i] * sep_std[...,0] + sep_mean[...,0]\n",
    "    else:\n",
    "        temp_pred_unnorm = pred[...,i] * sep_std[...,i] + sep_mean[...,i]\n",
    "    pred_unnorm.append(temp_pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get & process high-SNR data from previously loaded dataset\n",
    "highres_data = highsnr_val_dset._data\n",
    "if highres_data is not None:\n",
    "    highres_data = ignore_pixels(highres_data, highsnr_val_dset.get_img_sz()).copy()\n",
    "    if data_t_list is not None:\n",
    "        highres_data = highres_data[data_t_list].copy()\n",
    "\n",
    "    if \"target_idx_list\" in data_config and data_config[\"target_idx_list\"] is not None:\n",
    "        highres_data = highres_data[..., data_config[\"target_idx_list\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "Compute metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_range_inv_psnr(\n",
    "    pred: np.ndarray,\n",
    "    target: np.ndarray,\n",
    ") -> float:\n",
    "    \"\"\"Compute the average range-invariant PSNR.\"\"\"\n",
    "    psnr_arr = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        psnr_arr.append(scale_invariant_psnr(pred[i], target[i]))\n",
    "    return np.mean(psnr_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if highres_data is not None:\n",
    "    print(f'{DataSplitType.name(eval_datasplit_type)}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "    psnr_list = [avg_range_inv_psnr(highres_data[...,k], pred_unnorm[k]) for k in range(len(pred_unnorm))]\n",
    "    highres_norm = (highres_data - sep_mean) / sep_std\n",
    "    # care_ssim_list = multiscale_ssim(highres_norm, pred)\n",
    "    print(f\"PSNR on Highres: {' '.join([str(x) for x in psnr_list])}, avg: {np.mean(psnr_list)}\")\n",
    "    # print(f\"CARE-SSIM on Highres: {' '.join([str(np.round(x,3)) for x in care_ssim_list])}, avg: {np.mean(care_ssim_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_arr = []\n",
    "psnr_arr = []\n",
    "rinv_psnr_arr = []\n",
    "ssim_arr = []\n",
    "for ch_id in range(pred.shape[-1]):\n",
    "    rmse =np.sqrt(((pred[...,ch_id] - tar_normalized[...,ch_id])**2).reshape(len(pred),-1).mean(axis=1))\n",
    "    rmse_arr.append(rmse)\n",
    "    psnr = avg_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy())\n",
    "    rinv_psnr = avg_range_inv_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy())\n",
    "    ssim_mean, ssim_std = avg_ssim(tar[...,ch_id], pred_unnorm[ch_id])\n",
    "    psnr_arr.append(psnr)\n",
    "    rinv_psnr_arr.append(rinv_psnr)\n",
    "    ssim_arr.append((ssim_mean,ssim_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{DataSplitType.name(eval_datasplit_type)}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "print('Rec Loss: ', np.round(rec_loss.mean(),3) )\n",
    "print('RMSE: ', ' <--> '.join([str(np.mean(x).round(3)) for x in rmse_arr]))\n",
    "print('PSNR: ', ' <--> '.join([str(x) for x in psnr_arr]))\n",
    "print('RangeInvPSNR: ',' <--> '.join([str(x) for x in rinv_psnr_arr]))\n",
    "print('SSIM: ',' <--> '.join([f'{round(x,3)}Â±{round(y,4)}' for (x,y) in ssim_arr]))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_lvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
