{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First try to train a λSplit model\n",
    "\n",
    "In this notebook we try to train a λSplit model for the first time.\n",
    "\n",
    "This will require to add new parameters to the existing configs and maybe change the behavior or value of some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Literal, Optional\n",
    "\n",
    "from careamics.config import DataConfig, TrainingConfig\n",
    "from careamics.config import VAEAlgorithmConfig\n",
    "from careamics.config.architectures import LVAEModel\n",
    "from careamics.config.likelihood_model import (\n",
    "    GaussianLikelihoodConfig,\n",
    "    NMLikelihoodConfig,\n",
    ")\n",
    "from careamics.config.loss_model import LVAELossConfig, KLLossConfig\n",
    "from careamics.config.nm_model import GaussianMixtureNMConfig, MultiChannelNMConfig\n",
    "from careamics.config.optimizer_models import LrSchedulerModel, OptimizerModel\n",
    "from careamics.lightning import VAEModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "num_bins = 32 # TODO: add to some DataConfig --> add checks for consistency\n",
    "\"\"\"Number of bins for discretization of spectra.\"\"\"\n",
    "target_channels: int = 3\n",
    "\"\"\"Number of fluorophores to unmix.\"\"\"\n",
    "fluorophores: list[str] = [\"mTurquoise\", \"EGFP\", \"EYFP\"]\n",
    "\"\"\"List of fluorophores to unmix.\"\"\"\n",
    "wavelength_range: tuple[int, int] = (460, 550)\n",
    "\"\"\"Wavelength range of the spectral image.\"\"\"\n",
    "loss_type: Optional[Literal[\"musplit\", \"denoisplit\", \"denoisplit_musplit\", \"lambdasplit\"]] = \"lambdasplit\"\n",
    "\"\"\"The type of reconstruction loss (i.e., likelihood) to use.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Parameters\n",
    "batch_size: int = 32\n",
    "\"\"\"The batch size for training.\"\"\"\n",
    "patch_size: list[int] = [64, 64]\n",
    "\"\"\"Spatial size of the input patches.\"\"\"\n",
    "norm_strategy: Literal[\"channel-wise\", \"global\"] = \"channel-wise\"\n",
    "\"\"\"Normalization strategy for the input data.\"\"\"\n",
    "DATA_DIR = \"/group/jug/federico/microsim/BIOSR_spectral_data/2410/v1/imgs/digital/\"\n",
    "\"\"\"Directory containing the input data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "lr: float = 1e-3\n",
    "\"\"\"The learning rate for training.\"\"\"\n",
    "lr_scheduler_patience: int = 30\n",
    "\"\"\"The patience for the learning rate scheduler.\"\"\"\n",
    "earlystop_patience: int = 200\n",
    "\"\"\"The patience for the learning rate scheduler.\"\"\"\n",
    "max_epochs: int = 400\n",
    "\"\"\"The maximum number of epochs to train for.\"\"\"\n",
    "num_workers: int = 4\n",
    "\"\"\"The number of workers to use for data loading.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional not to touch parameters\n",
    "multiscale_count: int = 1\n",
    "\"\"\"The number of LC inputs plus one (the actual input).\"\"\"\n",
    "predict_logvar: Optional[Literal[\"pixelwise\"]] = None\n",
    "\"\"\"Whether to compute also the log-variance as LVAE output.\"\"\"\n",
    "nm_paths: Optional[tuple[str]] = [\n",
    "    \"/group/jug/ashesh/training_pre_eccv/noise_model/2402/221/GMMNoiseModel_ER-GT_all.mrc__6_4_Clip0.0-1.0_Sig0.125_UpNone_Norm0_bootstrap.npz\",\n",
    "    \"/group/jug/ashesh/training_pre_eccv/noise_model/2402/225/GMMNoiseModel_Microtubules-GT_all.mrc__6_4_Clip0.0-1.0_Sig0.125_UpNone_Norm0_bootstrap.npz\",\n",
    "]\n",
    "\"\"\"The paths to the pre-trained noise models for the different channels.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set up configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = TrainingConfig(\n",
    "    num_epochs=max_epochs,\n",
    "    precision=\"16-mixed\",\n",
    "    logger=\"wandb\",\n",
    "    gradient_clip_algorithm= \"value\",\n",
    "    grad_clip_norm_value=0.5,\n",
    "    lr=lr,\n",
    "    lr_scheduler_patience=lr_scheduler_patience,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"CYX\",\n",
    "    patch_size=patch_size,\n",
    "    batch_size=batch_size,\n",
    "    transforms=[],\n",
    "    norm_strategy=norm_strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from careamics.dataset import InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [\n",
    "    Path(DATA_DIR) / fname \n",
    "    for fname in glob.glob(os.path.join(DATA_DIR, \"*.tif\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = InMemoryDataset(\n",
    "    data_config=data_config,\n",
    "    inputs=fnames,\n",
    ")\n",
    "val_dset = train_dset.split_dataset(percentage=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_collate_fn(batch: list[torch.Tensor, None]) -> torch.Tensor:\n",
    "    inputs = [item[0] for item in batch]\n",
    "    inputs = torch.stack([torch.from_numpy(input_array) for input_array in inputs], dim=0)\n",
    "    return inputs, None\n",
    "\n",
    "train_dloader = DataLoader(\n",
    "    train_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    collate_fn=unsupervised_collate_fn\n",
    ")\n",
    "val_dloader = DataLoader(\n",
    "    val_dset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers, \n",
    "    collate_fn=unsupervised_collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lambda_split_lightning_model(\n",
    "    algorithm: str,\n",
    "    loss_type: str,\n",
    "    img_size: int,\n",
    "    target_ch: int,\n",
    "    fluorophores: list[str],\n",
    "    NM_paths: Optional[list[Path]] = None,\n",
    "    training_config: TrainingConfig = TrainingConfig(),\n",
    "    data_mean: Optional[torch.Tensor] = None,\n",
    "    data_std: Optional[torch.Tensor] = None, \n",
    ") -> VAEModule:\n",
    "    \"\"\"Instantiate the lambdaSplit lightining model.\"\"\"\n",
    "    # Model config\n",
    "    lvae_config = LVAEModel(\n",
    "        architecture=\"LVAE\",\n",
    "        algorithm_type=\"unsupervised\",\n",
    "        input_shape=img_size,\n",
    "        multiscale_count=1,\n",
    "        z_dims=[128, 128, 128, 128],\n",
    "        output_channels=target_ch,\n",
    "        predict_logvar=None,\n",
    "        analytical_kl=False,\n",
    "        fluorophores=fluorophores,\n",
    "        wv_range=wavelength_range,\n",
    "        num_bins=32,\n",
    "        ref_learnable=False,\n",
    "    )\n",
    "    \n",
    "    # Loss config\n",
    "    kl_loss_config = KLLossConfig(\n",
    "        rescaling=\"latent_dim\",\n",
    "        aggregation=\"mean\",\n",
    "        free_bits_coeff=0.0,\n",
    "    )\n",
    "    loss_config = LVAELossConfig(\n",
    "        loss_type=loss_type,\n",
    "        kl_params=kl_loss_config.model_dump(), # TODO: why tf needs model dump?\n",
    "    )\n",
    "\n",
    "    # Likelihoods configs\n",
    "    # gaussian likelihood\n",
    "    if loss_type in [\"musplit\", \"denoisplit_musplit\", \"lambdasplit\"]:\n",
    "        gaussian_lik_config = GaussianLikelihoodConfig(\n",
    "            predict_logvar=predict_logvar,\n",
    "            logvar_lowerbound=-5.0,  # TODO: find a better way to fix this\n",
    "        )\n",
    "    else:\n",
    "        gaussian_lik_config = None\n",
    "    # noise model likelihood\n",
    "    if loss_type in [\"denoisplit\", \"denoisplit_musplit\"]:\n",
    "        assert NM_paths is not None, \"A path to a pre-trained noise model is required.\"\n",
    "        gmm_list = []\n",
    "        for NM_path in NM_paths:\n",
    "            gmm_list.append(\n",
    "                GaussianMixtureNMConfig(\n",
    "                    model_type=\"GaussianMixtureNoiseModel\",\n",
    "                    path=NM_path,\n",
    "                )\n",
    "            )\n",
    "        noise_model_config = MultiChannelNMConfig(noise_models=gmm_list)\n",
    "        nm_lik_config = NMLikelihoodConfig(data_mean=data_mean, data_std=data_std)\n",
    "    else:\n",
    "        noise_model_config = None\n",
    "        nm_lik_config = None\n",
    "\n",
    "    # Other configs\n",
    "    opt_config = OptimizerModel(\n",
    "        name=\"Adamax\",\n",
    "        parameters={\n",
    "            \"lr\": training_config.lr,\n",
    "            \"weight_decay\": 0,\n",
    "        },\n",
    "    )\n",
    "    lr_scheduler_config = LrSchedulerModel(\n",
    "        name=\"ReduceLROnPlateau\",\n",
    "        parameters={\n",
    "            \"mode\": \"min\",\n",
    "            \"factor\": 0.5,\n",
    "            \"patience\": training_config.lr_scheduler_patience,\n",
    "            \"verbose\": True,\n",
    "            \"min_lr\": 1e-12,\n",
    "        },\n",
    "    )\n",
    " \n",
    "    # Group all configs & create model\n",
    "    vae_config = VAEAlgorithmConfig(\n",
    "        algorithm_type=\"vae\",\n",
    "        algorithm=algorithm,\n",
    "        model=lvae_config,\n",
    "        loss=loss_config.model_dump(), # TODO: why tf needs model dump?\n",
    "        gaussian_likelihood=gaussian_lik_config,\n",
    "        noise_model=noise_model_config,\n",
    "        noise_model_likelihood=nm_lik_config,\n",
    "        optimizer=opt_config,\n",
    "        lr_scheduler=lr_scheduler_config,\n",
    "    )\n",
    "    return VAEModule(algorithm_config=vae_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightning_model = create_lambda_split_lightning_model(\n",
    "    algorithm=\"lambdasplit\",\n",
    "    loss_type=loss_type,\n",
    "    img_size=patch_size[0],\n",
    "    target_ch=target_channels,\n",
    "    fluorophores=fluorophores,\n",
    "    training_config=training_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Set utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import socket\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from careamics.utils.io_utils import get_git_status, get_workdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/group/jug/federico/lambdasplit_training/\"\n",
    "algo = \"lambdasplit\"\n",
    "lc_tag = \"with\" if multiscale_count > 1 else \"no\"\n",
    "workdir, exp_tag = get_workdir(ROOT_DIR, f\"{algo}_{lc_tag}_LC\")\n",
    "print(f\"Current workdir: {workdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logger\n",
    "custom_logger = WandbLogger(\n",
    "    name=os.path.join(socket.gethostname(), exp_tag),\n",
    "    save_dir=workdir,\n",
    "    project=\"_\".join((\"careamics\", algo)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configs and git status (for debugging)\n",
    "algo_config = lightning_model.algorithm_config\n",
    "\n",
    "with open(os.path.join(workdir, \"git_config.json\"), \"w\") as f:\n",
    "    json.dump(get_git_status(), f, indent=4)\n",
    "\n",
    "with open(os.path.join(workdir, \"algorithm_config.json\"), \"w\") as f:\n",
    "    f.write(algo_config.model_dump_json(indent=4))\n",
    "\n",
    "with open(os.path.join(workdir, \"training_config.json\"), \"w\") as f:\n",
    "    f.write(training_config.model_dump_json(indent=4))\n",
    "\n",
    "with open(os.path.join(workdir, \"data_config.json\"), \"w\") as f:\n",
    "    f.write(data_config.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Configs in WanDB\n",
    "custom_logger.experiment.config.update({\"algorithm\": algo_config.model_dump()})\n",
    "custom_logger.experiment.config.update({\"training\": training_config.model_dump()})\n",
    "custom_logger.experiment.config.update({\"data\": data_config.model_dump()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks (e.g., ModelCheckpoint, EarlyStopping, etc.)\n",
    "custom_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=1e-6,\n",
    "        patience=training_config.earlystop_patience,\n",
    "        mode=\"min\",\n",
    "        verbose=True,\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        dirpath=workdir,\n",
    "        filename=\"best-{epoch}\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_top_k=1,\n",
    "        save_last=True,\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval=\"epoch\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=training_config.num_epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_progress_bar=True,\n",
    "    logger=custom_logger,\n",
    "    callbacks=custom_callbacks,\n",
    "    precision=training_config.precision,\n",
    "    gradient_clip_val=training_config.gradient_clip_val,  # only works with `accelerator=\"gpu\"`\n",
    "    gradient_clip_algorithm=training_config.gradient_clip_algorithm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    train_dataloaders=train_dloader,\n",
    "    val_dataloaders=val_dloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_lvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
